#!/usr/bin/env npx tsx
/**
 * {{ .Name }} - MCP Mesh LLM Agent
 *
 * {{ if .Description }}{{ .Description }}{{ else }}A MCP Mesh LLM agent generated using meshctl scaffold.{{ end }}
 */

import { FastMCP } from "fastmcp";
import { mesh } from "@mcpmesh/sdk";
import { z } from "zod";

// FastMCP server instance
const server = new FastMCP({
  name: "{{ toPascalCase .Name }} Service",
  version: "1.0.0",
});

// ===== CONTEXT SCHEMA =====

const {{ toPascalCase .Name }}Context = z.object({
  inputText: z.string().describe("Input text to process"),
  // Add your context fields here
  // userId: z.string().describe("User identifier"),
  // metadata: z.record(z.any()).optional().describe("Additional metadata"),
});

{{ if eq .ResponseFormat "json" }}
// ===== RESPONSE SCHEMA =====

const {{ toPascalCase .Name }}Response = z.object({
  result: z.string().describe("Processing result"),
  // Add additional response fields as needed
  // confidence: z.number().min(0).max(1).describe("Confidence score"),
  // reasoning: z.string().describe("Explanation of the result"),
});
{{ end }}

// ===== LLM TOOL =====

server.addTool(
  mesh.llm({
    name: "{{ toSnakeCase .Name }}",
    capability: "{{ toSnakeCase .Name }}",
    description: "{{ if .Description }}{{ .Description }}{{ else }}Process input using LLM{{ end }}",
    tags: {{ if .Tags }}{{ toJSON .Tags }}{{ else }}["llm"]{{ end }},

    // LLM Configuration
    provider: { capability: "llm", tags: {{ toJSON .ProviderTags }} },
    maxIterations: {{ .MaxIterations }},
    systemPrompt: "file://prompts/{{ .Name }}.hbs",
    contextParam: "{{ .ContextParam }}",

    // Tool filtering - which mesh tools the LLM can access
    filter: {{ if .ToolFilter }}{{ toJSON .ToolFilter }}{{ else }}[]{{ end }},
    filterMode: "{{ .FilterMode }}",

    // Input/output schemas
    parameters: z.object({
      {{ .ContextParam }}: {{ toPascalCase .Name }}Context,
    }),
{{ if eq .ResponseFormat "json" }}
    returns: {{ toPascalCase .Name }}Response,
{{ end }}

    // Handler receives injected LLM agent
    execute: async ({ {{ .ContextParam }} }, { llm }) => {
      return await llm("Process the input based on the context provided");
    },
  })
);

// ===== AGENT CONFIGURATION =====

const agent = mesh(server, {
  name: "{{ .Name }}",
  port: {{ .Port }},
});

// No server.start() needed!
// Mesh SDK automatically handles:
// - FastMCP server startup
// - LLM provider injection
// - HTTP server configuration
// - Service registration with mesh registry
