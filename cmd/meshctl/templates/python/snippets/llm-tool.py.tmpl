# ===== {{ .ToolName | toUpperSnakeCase }} CONTEXT MODEL =====

class {{ .ToolName | toPascalCase }}Context(BaseModel):
    """Context for {{ .ToolName }} LLM processing."""

    input_text: str = Field(..., description="Input text to process")
    # Add additional context fields as needed

{{ if eq .ResponseFormat "json" }}

# ===== {{ .ToolName | toUpperSnakeCase }} RESPONSE MODEL =====

class {{ .ToolName | toPascalCase }}Response(BaseModel):
    """Structured response from {{ .ToolName }}."""

    result: str = Field(..., description="Processing result")
    # Add additional response fields as needed
{{ end }}

# ===== {{ .ToolName | toUpperSnakeCase }} LLM TOOL =====

@app.tool()
@mesh.llm(
    filter={{ if .ToolFilter }}{{ toJSON .ToolFilter }}{{ else }}None{{ end }},
    filter_mode="{{ .FilterMode | default "all" }}",
    provider={"capability": "llm", "tags": {{ toJSON .ProviderTags }}},
    max_iterations={{ .MaxIterations | default 1 }},
    system_prompt={{ if .SystemPromptIsFile }}"{{ .SystemPrompt }}"{{ else if .SystemPrompt }}"""{{ .SystemPrompt }}"""{{ else }}"""You are an AI assistant for {{ .ToolName }}.

{{ .ToolDescription | default "Process the input and provide a helpful response." }}

Analyze the provided context and respond appropriately."""{{ end }},
    context_param="{{ .ContextParam | default "ctx" }}",
    response_format="{{ .ResponseFormat | default "text" }}",
)
@mesh.tool(
    capability="{{ .ToolName }}",
    description="{{ .ToolDescription | default "LLM-powered tool" }}",
)
def {{ .ToolName }}(
    {{ .ContextParam | default "ctx" }}: {{ .ToolName | toPascalCase }}Context,
    llm: mesh.MeshLlmAgent = None,
){{ if eq .ResponseFormat "json" }} -> {{ .ToolName | toPascalCase }}Response{{ else }} -> str{{ end }}:
    """
    {{ .ToolDescription | default "LLM-powered tool" }}.

    Args:
        {{ .ContextParam | default "ctx" }}: Context containing input data for processing
        llm: Injected LLM agent (provided by mesh)

    Returns:
        {{ if eq .ResponseFormat "json" }}Structured response with processing results{{ else }}Processing result as text{{ end }}
    """
    return llm("Process the input based on the context provided")
